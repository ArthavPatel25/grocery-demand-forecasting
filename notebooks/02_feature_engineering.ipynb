{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466bf5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANADIAN GROCERY DEMAND FORECASTING - FEATURE ENGINEERING\n",
      "Libraries imported successfully!\n",
      "Feature engineering started: 2025-09-05 13:37:53\n"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING FOR DEMAND FORECASTING\n",
    "\n",
    "print(\"CANADIAN GROCERY DEMAND FORECASTING - FEATURE ENGINEERING\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Feature engineering started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "062ca1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved datasets...\n",
      "Current working directory: c:\\Users\\artha\\OneDrive\\Desktop\\grocery-demand-forecasting\\notebooks\n",
      "Looking for data in: c:\\Users\\artha\\OneDrive\\Desktop\\grocery-demand-forecasting\\data\\raw\n",
      "Files in data/raw/: ['products_data.csv', 'sales_data.csv', 'stores_data.csv']\n",
      "Data loaded successfully!\n",
      "Sales records: 89,482\n",
      "Date range: 2022-01-01 to 2023-12-31\n",
      "Stores: 25\n",
      "Products: 123\n",
      "\n",
      "Data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>sales_quantity</th>\n",
       "      <th>price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>promotion_flag</th>\n",
       "      <th>chain</th>\n",
       "      <th>province</th>\n",
       "      <th>store_size</th>\n",
       "      <th>population_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>ST_002</td>\n",
       "      <td>PR_0029</td>\n",
       "      <td>No Name Ground Beef/kg</td>\n",
       "      <td>Meat</td>\n",
       "      <td>No Name</td>\n",
       "      <td>70</td>\n",
       "      <td>9.16</td>\n",
       "      <td>641.20</td>\n",
       "      <td>0</td>\n",
       "      <td>Metro</td>\n",
       "      <td>BC</td>\n",
       "      <td>Large</td>\n",
       "      <td>Suburban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>ST_013</td>\n",
       "      <td>PR_0048</td>\n",
       "      <td>National Brand Bananas/kg</td>\n",
       "      <td>Produce</td>\n",
       "      <td>National Brand</td>\n",
       "      <td>10</td>\n",
       "      <td>1.57</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0</td>\n",
       "      <td>FreshCo</td>\n",
       "      <td>NS</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Suburban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>ST_003</td>\n",
       "      <td>PR_0074</td>\n",
       "      <td>No Name Bagels 6pk</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>No Name</td>\n",
       "      <td>99</td>\n",
       "      <td>3.66</td>\n",
       "      <td>362.34</td>\n",
       "      <td>0</td>\n",
       "      <td>Metro</td>\n",
       "      <td>PE</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>ST_020</td>\n",
       "      <td>PR_0115</td>\n",
       "      <td>President's Choice Olive Oil 500ml</td>\n",
       "      <td>Pantry</td>\n",
       "      <td>President's Choice</td>\n",
       "      <td>76</td>\n",
       "      <td>7.47</td>\n",
       "      <td>567.72</td>\n",
       "      <td>0</td>\n",
       "      <td>FreshCo</td>\n",
       "      <td>NS</td>\n",
       "      <td>Small</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>ST_014</td>\n",
       "      <td>PR_0078</td>\n",
       "      <td>National Brand Croissants 4pk</td>\n",
       "      <td>Bakery</td>\n",
       "      <td>National Brand</td>\n",
       "      <td>42</td>\n",
       "      <td>5.65</td>\n",
       "      <td>237.30</td>\n",
       "      <td>0</td>\n",
       "      <td>Sobeys</td>\n",
       "      <td>MB</td>\n",
       "      <td>Large</td>\n",
       "      <td>Urban</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date store_id product_id                        product_name category  \\\n",
       "0 2022-01-01   ST_002    PR_0029              No Name Ground Beef/kg     Meat   \n",
       "1 2022-01-01   ST_013    PR_0048           National Brand Bananas/kg  Produce   \n",
       "2 2022-01-01   ST_003    PR_0074                  No Name Bagels 6pk   Bakery   \n",
       "3 2022-01-01   ST_020    PR_0115  President's Choice Olive Oil 500ml   Pantry   \n",
       "4 2022-01-01   ST_014    PR_0078       National Brand Croissants 4pk   Bakery   \n",
       "\n",
       "                brand  sales_quantity  price  revenue  promotion_flag  \\\n",
       "0             No Name              70   9.16   641.20               0   \n",
       "1      National Brand              10   1.57    15.70               0   \n",
       "2             No Name              99   3.66   362.34               0   \n",
       "3  President's Choice              76   7.47   567.72               0   \n",
       "4      National Brand              42   5.65   237.30               0   \n",
       "\n",
       "     chain province store_size population_density  \n",
       "0    Metro       BC      Large           Suburban  \n",
       "1  FreshCo       NS     Medium           Suburban  \n",
       "2    Metro       PE     Medium              Urban  \n",
       "3  FreshCo       NS      Small              Urban  \n",
       "4   Sobeys       MB      Large              Urban  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data info:\n",
      "Sales data shape: (89482, 14)\n",
      "Stores data shape: (25, 6)\n",
      "Products data shape: (123, 5)\n"
     ]
    }
   ],
   "source": [
    "#LOAD PREVIOUSLY GENERATED DATA\n",
    "print(\"Loading saved datasets...\")\n",
    "\n",
    "import os\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# We're in notebooks/ but need to go up one level to access data/\n",
    "data_path = '../data/raw/'\n",
    "print(f\"Looking for data in: {os.path.abspath(data_path)}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Files in data/raw/: {os.listdir(data_path)}\")\n",
    "    \n",
    "    # Load the datasets with correct relative paths\n",
    "    sales_df = pd.read_csv('../data/raw/sales_data.csv')\n",
    "    stores_df = pd.read_csv('../data/raw/stores_data.csv')\n",
    "    products_df = pd.read_csv('../data/raw/products_data.csv')\n",
    "    \n",
    "    # Convert date column\n",
    "    sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "    \n",
    "    print(f\"Data loaded successfully!\")\n",
    "    print(f\"Sales records: {len(sales_df):,}\")\n",
    "    print(f\"Date range: {sales_df['date'].min().date()} to {sales_df['date'].max().date()}\")\n",
    "    print(f\"Stores: {sales_df['store_id'].nunique()}\")\n",
    "    print(f\"Products: {sales_df['product_id'].nunique()}\")\n",
    "    \n",
    "    # Quick data check\n",
    "    print(\"\\nData sample:\")\n",
    "    display(sales_df.head())\n",
    "    print(f\"\\nData info:\")\n",
    "    print(f\"Sales data shape: {sales_df.shape}\")\n",
    "    print(f\"Stores data shape: {stores_df.shape}\")\n",
    "    print(f\"Products data shape: {products_df.shape}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Files not found: {e}\")\n",
    "    print(\"Let me check the directory structure...\")\n",
    "    \n",
    "    # Check parent directory structure\n",
    "    parent_dir = '..'\n",
    "    print(f\"\\nContents of parent directory:\")\n",
    "    for item in os.listdir(parent_dir):\n",
    "        item_path = os.path.join(parent_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"{item}/\")\n",
    "        else:\n",
    "            print(f\"{item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423a7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating advanced features for ML models...\n",
      "Starting comprehensive feature engineering...\n",
      "Creating time-based features...\n",
      "ðŸ‡¨ðŸ‡¦ Adding Canadian holiday features...\n",
      "Creating lag and rolling features...\n",
      "Creating rolling window features...\n",
      "Creating price and promotion features...\n",
      "Creating store and product aggregation features...\n",
      "Creating market share and relative features...\n",
      "Creating product lifecycle features...\n",
      "Feature engineering complete!\n",
      "\n",
      "FEATURE ENGINEERING SUMMARY:\n",
      "Original features: 14\n",
      "New features: 87\n",
      "Features added: 73\n",
      "Total rows: 89,482\n"
     ]
    }
   ],
   "source": [
    "# COMPREHENSIVE FEATURE ENGINEERING\n",
    "print(\"Creating advanced features for ML models...\")\n",
    "\n",
    "def create_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Create comprehensive feature set for demand forecasting\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['store_id', 'product_id', 'date'])\n",
    "    \n",
    "    print(\"Creating time-based features...\")\n",
    "    \n",
    "    # === TIME-BASED FEATURES ===\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    \n",
    "    # Weekend and weekday indicators\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['is_monday'] = (df['day_of_week'] == 0).astype(int)\n",
    "    df['is_friday'] = (df['day_of_week'] == 4).astype(int)\n",
    "    \n",
    "    # Month patterns\n",
    "    df['is_month_start'] = (df['day'] <= 7).astype(int)\n",
    "    df['is_month_middle'] = ((df['day'] > 7) & (df['day'] <= 21)).astype(int)\n",
    "    df['is_month_end'] = (df['day'] > 21).astype(int)\n",
    "    \n",
    "    # Seasonal features (cyclical encoding for better ML performance)\n",
    "    df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['sin_day_of_week'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['cos_day_of_week'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['sin_day_of_year'] = np.sin(2 * np.pi * df['date'].dt.dayofyear / 365)\n",
    "    df['cos_day_of_year'] = np.cos(2 * np.pi * df['date'].dt.dayofyear / 365)\n",
    "    \n",
    "    print(\"ðŸ‡¨ðŸ‡¦ Adding Canadian holiday features...\")\n",
    "    \n",
    "    # === CANADIAN HOLIDAYS ===\n",
    "    def is_canadian_holiday(date):\n",
    "        \"\"\"Check if date is a Canadian statutory holiday\"\"\"\n",
    "        month, day = date.month, date.day\n",
    "        \n",
    "        # Fixed holidays\n",
    "        holidays = {\n",
    "            (1, 1): 'New Year',\n",
    "            (7, 1): 'Canada Day', \n",
    "            (12, 25): 'Christmas',\n",
    "            (12, 26): 'Boxing Day'\n",
    "        }\n",
    "        \n",
    "        # Floating holidays (simplified)\n",
    "        if month == 2 and 10 <= day <= 16:  # Family Day\n",
    "            return 'Family Day'\n",
    "        if month == 5 and 18 <= day <= 24:  # Victoria Day\n",
    "            return 'Victoria Day'\n",
    "        if month == 9 and 1 <= day <= 7:   # Labour Day\n",
    "            return 'Labour Day'\n",
    "        if month == 10 and 8 <= day <= 14: # Thanksgiving\n",
    "            return 'Thanksgiving'\n",
    "        if month == 11 and day == 11:      # Remembrance Day\n",
    "            return 'Remembrance Day'\n",
    "            \n",
    "        return holidays.get((month, day), None)\n",
    "    \n",
    "    df['holiday_name'] = df['date'].apply(is_canadian_holiday)\n",
    "    df['is_holiday'] = (df['holiday_name'].notna()).astype(int)\n",
    "    df['is_major_holiday'] = df['holiday_name'].isin(['Christmas', 'New Year', 'Canada Day']).astype(int)\n",
    "    \n",
    "    # Days before/after holidays\n",
    "    df['days_to_holiday'] = 0\n",
    "    df['days_from_holiday'] = 0\n",
    "    \n",
    "    holiday_dates = df[df['is_holiday'] == 1]['date'].unique()\n",
    "    for holiday_date in holiday_dates:\n",
    "        mask_before = (df['date'] >= holiday_date - timedelta(days=3)) & (df['date'] < holiday_date)\n",
    "        mask_after = (df['date'] > holiday_date) & (df['date'] <= holiday_date + timedelta(days=3))\n",
    "        \n",
    "        df.loc[mask_before, 'days_to_holiday'] = (holiday_date - df.loc[mask_before, 'date']).dt.days\n",
    "        df.loc[mask_after, 'days_from_holiday'] = (df.loc[mask_after, 'date'] - holiday_date).dt.days\n",
    "    \n",
    "    print(\"Creating lag and rolling features...\")\n",
    "    \n",
    "    # === LAG FEATURES ===\n",
    "    # Sort by store, product, and date for proper lag calculation\n",
    "    df = df.sort_values(['store_id', 'product_id', 'date'])\n",
    "    \n",
    "    # Sales quantity lags\n",
    "    for lag in [1, 3, 7, 14, 30]:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby(['store_id', 'product_id'])['sales_quantity'].shift(lag)\n",
    "    \n",
    "    # Revenue lags\n",
    "    for lag in [1, 7, 30]:\n",
    "        df[f'revenue_lag_{lag}'] = df.groupby(['store_id', 'product_id'])['revenue'].shift(lag)\n",
    "    \n",
    "    # Price lags\n",
    "    df['price_lag_1'] = df.groupby(['store_id', 'product_id'])['price'].shift(1)\n",
    "    df['price_lag_7'] = df.groupby(['store_id', 'product_id'])['price'].shift(7)\n",
    "    \n",
    "    print(\"Creating rolling window features...\")\n",
    "    \n",
    "    # === ROLLING WINDOW FEATURES ===\n",
    "    for window in [3, 7, 14, 30]:\n",
    "        # Rolling means\n",
    "        df[f'sales_rolling_mean_{window}'] = df.groupby(['store_id', 'product_id'])['sales_quantity'].rolling(\n",
    "            window=window, min_periods=1).mean().values\n",
    "        \n",
    "        # Rolling standard deviations (volatility)\n",
    "        df[f'sales_rolling_std_{window}'] = df.groupby(['store_id', 'product_id'])['sales_quantity'].rolling(\n",
    "            window=window, min_periods=1).std().values\n",
    "        \n",
    "        # Rolling max/min\n",
    "        df[f'sales_rolling_max_{window}'] = df.groupby(['store_id', 'product_id'])['sales_quantity'].rolling(\n",
    "            window=window, min_periods=1).max().values\n",
    "        df[f'sales_rolling_min_{window}'] = df.groupby(['store_id', 'product_id'])['sales_quantity'].rolling(\n",
    "            window=window, min_periods=1).min().values\n",
    "    \n",
    "    print(\"Creating price and promotion features...\")\n",
    "    \n",
    "    # === PRICE FEATURES ===\n",
    "    df['price_change'] = df['price'] - df['price_lag_1']\n",
    "    df['price_change_pct'] = df['price_change'] / df['price_lag_1']\n",
    "    df['price_vs_avg'] = df['price'] / df.groupby('product_id')['price'].transform('mean')\n",
    "    \n",
    "    # Price elasticity indicators\n",
    "    df['is_price_drop'] = (df['price_change'] < -0.10).astype(int)\n",
    "    df['is_price_increase'] = (df['price_change'] > 0.10).astype(int)\n",
    "    \n",
    "    # === PROMOTION FEATURES ===\n",
    "    df['promotion_lag_1'] = df.groupby(['store_id', 'product_id'])['promotion_flag'].shift(1)\n",
    "    df['promotion_lag_7'] = df.groupby(['store_id', 'product_id'])['promotion_flag'].shift(7)\n",
    "    \n",
    "    # Days since last promotion\n",
    "    df['days_since_promotion'] = df.groupby(['store_id', 'product_id'])['promotion_flag'].apply(\n",
    "        lambda x: (x == 0).cumsum() - (x == 0).cumsum().where(x == 1).ffill().fillna(0)\n",
    "    ).values\n",
    "    \n",
    "    # Promotion frequency (in last 30 days)\n",
    "    df['promotion_frequency_30d'] = df.groupby(['store_id', 'product_id'])['promotion_flag'].rolling(\n",
    "        window=30, min_periods=1).sum().values\n",
    "    \n",
    "    print(\"Creating store and product aggregation features...\")\n",
    "    \n",
    "    # === AGGREGATION FEATURES ===\n",
    "    # Store-level daily totals\n",
    "    df['store_daily_sales'] = df.groupby(['store_id', 'date'])['sales_quantity'].transform('sum')\n",
    "    df['store_daily_revenue'] = df.groupby(['store_id', 'date'])['revenue'].transform('sum')\n",
    "    df['store_daily_transactions'] = df.groupby(['store_id', 'date'])['sales_quantity'].transform('count')\n",
    "    \n",
    "    # Product-level daily totals (across all stores)\n",
    "    df['product_daily_sales'] = df.groupby(['product_id', 'date'])['sales_quantity'].transform('sum')\n",
    "    df['product_daily_revenue'] = df.groupby(['product_id', 'date'])['revenue'].transform('sum')\n",
    "    \n",
    "    # Category-level daily totals\n",
    "    df['category_daily_sales'] = df.groupby(['category', 'date'])['sales_quantity'].transform('sum')\n",
    "    df['category_daily_revenue'] = df.groupby(['category', 'date'])['revenue'].transform('sum')\n",
    "    \n",
    "    # Chain-level daily totals\n",
    "    df['chain_daily_sales'] = df.groupby(['chain', 'date'])['sales_quantity'].transform('sum')\n",
    "    \n",
    "    print(\"Creating market share and relative features...\")\n",
    "    \n",
    "    # === MARKET SHARE FEATURES ===\n",
    "    # Product's share of store sales\n",
    "    df['product_store_share'] = df['sales_quantity'] / df['store_daily_sales']\n",
    "    df['product_store_revenue_share'] = df['revenue'] / df['store_daily_revenue']\n",
    "    \n",
    "    # Store's share of product sales\n",
    "    df['store_product_share'] = df['sales_quantity'] / df['product_daily_sales']\n",
    "    \n",
    "    # Product's share of category sales\n",
    "    df['product_category_share'] = df['sales_quantity'] / df['category_daily_sales']\n",
    "    \n",
    "    # Store performance relative to chain\n",
    "    df['store_vs_chain_performance'] = df['store_daily_sales'] / df['chain_daily_sales']\n",
    "    \n",
    "    print(\"Creating product lifecycle features...\")\n",
    "    \n",
    "    # === PRODUCT LIFECYCLE FEATURES ===\n",
    "    # Days since product first appeared in store\n",
    "    df['product_age_in_store'] = df.groupby(['store_id', 'product_id'])['date'].transform(\n",
    "        lambda x: (x - x.min()).dt.days\n",
    "    )\n",
    "    \n",
    "    # Product velocity (average daily sales)\n",
    "    df['product_velocity'] = df.groupby(['store_id', 'product_id'])['sales_quantity'].transform('mean')\n",
    "    \n",
    "    print(\"Feature engineering complete!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Starting comprehensive feature engineering...\")\n",
    "engineered_df = create_advanced_features(sales_df)\n",
    "\n",
    "print(f\"\\nFEATURE ENGINEERING SUMMARY:\")\n",
    "print(f\"Original features: {sales_df.shape[1]}\")\n",
    "print(f\"New features: {engineered_df.shape[1]}\")\n",
    "print(f\"Features added: {engineered_df.shape[1] - sales_df.shape[1]}\")\n",
    "print(f\"Total rows: {len(engineered_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe89ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables for ML models...\n",
      "  Encoding store_id...\n",
      "    store_id: 25 unique values\n",
      "  Encoding product_id...\n",
      "    product_id: 123 unique values\n",
      "  Encoding category...\n",
      "    category: 6 unique values\n",
      "  Encoding brand...\n",
      "    brand: 3 unique values\n",
      "  Encoding chain...\n",
      "    chain: 7 unique values\n",
      "  Encoding province...\n",
      "    province: 10 unique values\n",
      "  Encoding store_size...\n",
      "    store_size: 3 unique values\n",
      "  Encoding population_density...\n",
      "    population_density: 3 unique values\n",
      "  Encoding holiday_name...\n",
      "    holiday_name: 10 unique values\n",
      "\n",
      "Categorical encoding complete!\n",
      "Encoded columns: 9\n",
      "\n",
      "FINAL FEATURE SET:\n",
      "Total features available: 94\n",
      "\n",
      "FEATURE BREAKDOWN:\n",
      "  Time features: 25\n",
      "  Lag features: 12\n",
      "  Rolling features: 16\n",
      "  Price features: 8\n",
      "  Promotion features: 5\n",
      "  Aggregation features: 14\n",
      "  Encoded features: 9\n"
     ]
    }
   ],
   "source": [
    "# CATEGORICAL VARIABLE ENCODING\n",
    "print(\"Encoding categorical variables for ML models...\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    \"\"\"\n",
    "    Encode categorical variables using Label Encoding\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    encoders = {}\n",
    "    \n",
    "    # Categorical columns to encode\n",
    "    categorical_columns = [\n",
    "        'store_id', 'product_id', 'category', 'brand', 'chain', \n",
    "        'province', 'store_size', 'population_density', 'holiday_name'\n",
    "    ]\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in df.columns:\n",
    "            print(f\"  Encoding {col}...\")\n",
    "            le = LabelEncoder()\n",
    "            \n",
    "            # Handle missing values\n",
    "            df[f'{col}_encoded'] = df[col].fillna('unknown')\n",
    "            df[f'{col}_encoded'] = le.fit_transform(df[f'{col}_encoded'])\n",
    "            \n",
    "            # Store encoder for later use\n",
    "            encoders[col] = le\n",
    "            \n",
    "            print(f\"    {col}: {len(le.classes_)} unique values\")\n",
    "    \n",
    "    return df, encoders\n",
    "\n",
    "# Apply categorical encoding\n",
    "engineered_df, label_encoders = encode_categorical_features(engineered_df)\n",
    "\n",
    "print(f\"\\nCategorical encoding complete!\")\n",
    "print(f\"Encoded columns: {len(label_encoders)}\")\n",
    "\n",
    "# Display feature summary\n",
    "print(f\"\\nFINAL FEATURE SET:\")\n",
    "feature_columns = [col for col in engineered_df.columns if col not in ['date', 'product_name']]\n",
    "print(f\"Total features available: {len(feature_columns)}\")\n",
    "\n",
    "# Group features by type\n",
    "time_features = [col for col in feature_columns if any(x in col for x in ['year', 'month', 'day', 'week', 'quarter', 'sin_', 'cos_', 'holiday', 'weekend'])]\n",
    "lag_features = [col for col in feature_columns if 'lag_' in col]\n",
    "rolling_features = [col for col in feature_columns if 'rolling_' in col]\n",
    "price_features = [col for col in feature_columns if 'price' in col]\n",
    "promotion_features = [col for col in feature_columns if 'promotion' in col]\n",
    "aggregation_features = [col for col in feature_columns if any(x in col for x in ['daily_', 'share', 'vs_'])]\n",
    "encoded_features = [col for col in feature_columns if '_encoded' in col]\n",
    "\n",
    "print(f\"\\nFEATURE BREAKDOWN:\")\n",
    "print(f\"  Time features: {len(time_features)}\")\n",
    "print(f\"  Lag features: {len(lag_features)}\")\n",
    "print(f\"  Rolling features: {len(rolling_features)}\")\n",
    "print(f\"  Price features: {len(price_features)}\")\n",
    "print(f\"  Promotion features: {len(promotion_features)}\")\n",
    "print(f\"  Aggregation features: {len(aggregation_features)}\")\n",
    "print(f\"  Encoded features: {len(encoded_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315677a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing feature quality and correlations...\n",
      "Analysis dataset: 89,482 rows\n",
      "Numerical features for analysis: 84\n",
      "Filled 337,351 missing values with median\n",
      "Calculating correlations with target variable...\n",
      "\n",
      "TOP 20 FEATURES CORRELATED WITH SALES:\n",
      " 1. sales_rolling_mean_3                | Correlation: 0.7309\n",
      " 2. sales_rolling_max_3                 | Correlation: 0.6678\n",
      " 3. product_category_share              | Correlation: 0.6555\n",
      " 4. revenue                             | Correlation: 0.6375\n",
      " 5. sales_rolling_mean_7                | Correlation: 0.6260\n",
      " 6. sales_rolling_mean_14               | Correlation: 0.5914\n",
      " 7. sales_rolling_mean_30               | Correlation: 0.5840\n",
      " 8. sales_rolling_min_3                 | Correlation: 0.5601\n",
      " 9. sales_rolling_max_7                 | Correlation: 0.5463\n",
      "10. product_daily_sales                 | Correlation: 0.5392\n",
      "11. store_daily_sales                   | Correlation: 0.5177\n",
      "12. product_velocity                    | Correlation: 0.5176\n",
      "13. sales_rolling_max_14                | Correlation: 0.4939\n",
      "14. sales_rolling_max_30                | Correlation: 0.4799\n",
      "15. store_daily_revenue                 | Correlation: 0.4594\n",
      "16. sales_rolling_std_30                | Correlation: 0.4569\n",
      "17. sales_rolling_std_14                | Correlation: 0.4507\n",
      "18. sales_rolling_std_7                 | Correlation: 0.4504\n",
      "19. sales_rolling_std_3                 | Correlation: 0.4327\n",
      "20. store_size_encoded                  | Correlation: 0.4147\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Absolute Correlation=%{x}<br>Features=%{y}<br>color=%{marker.color}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": {
           "bdata": "Hyf1Vqhj5z9YTSxX0F7lPzYH8fUV+uQ/FsIf78pm5D8oy9DrdwjkP6BhmsL97OI/43Qg2yiw4j9P4xjOWezhP9I3wX49e+E/IlIGBhpB4T8mB8Qn3ZDgPz5Y7VtRkOA/vLkSJkab3z/2DJyvLLfePwoR7EgpZt0/",
           "dtype": "f8"
          },
          "coloraxis": "coloraxis",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "orientation": "h",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "Hyf1Vqhj5z9YTSxX0F7lPzYH8fUV+uQ/FsIf78pm5D8oy9DrdwjkP6BhmsL97OI/43Qg2yiw4j9P4xjOWezhP9I3wX49e+E/IlIGBhpB4T8mB8Qn3ZDgPz5Y7VtRkOA/vLkSJkab3z/2DJyvLLfePwoR7EgpZt0/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "sales_rolling_mean_3",
          "sales_rolling_max_3",
          "product_category_share",
          "revenue",
          "sales_rolling_mean_7",
          "sales_rolling_mean_14",
          "sales_rolling_mean_30",
          "sales_rolling_min_3",
          "sales_rolling_max_7",
          "product_daily_sales",
          "store_daily_sales",
          "product_velocity",
          "sales_rolling_max_14",
          "sales_rolling_max_30",
          "store_daily_revenue"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "color"
          }
         },
         "colorscale": [
          [
           0,
           "#440154"
          ],
          [
           0.1111111111111111,
           "#482878"
          ],
          [
           0.2222222222222222,
           "#3e4989"
          ],
          [
           0.3333333333333333,
           "#31688e"
          ],
          [
           0.4444444444444444,
           "#26828e"
          ],
          [
           0.5555555555555556,
           "#1f9e89"
          ],
          [
           0.6666666666666666,
           "#35b779"
          ],
          [
           0.7777777777777778,
           "#6ece58"
          ],
          [
           0.8888888888888888,
           "#b5de2b"
          ],
          [
           1,
           "#fde725"
          ]
         ]
        },
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Top 15 Features Correlated with Sales Quantity"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Absolute Correlation"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Features"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FEATURES WITH HIGHEST VARIANCE:\n",
      " 1. category_daily_revenue              | Variance: 6.18e+06\n",
      " 2. store_daily_revenue                 | Variance: 5.06e+05\n",
      " 3. product_daily_revenue               | Variance: 1.20e+05\n",
      " 4. chain_daily_sales                   | Variance: 1.10e+05\n",
      " 5. category_daily_sales                | Variance: 8.00e+04\n",
      " 6. product_age_in_store                | Variance: 4.49e+04\n",
      " 7. revenue                             | Variance: 2.72e+04\n",
      " 8. revenue_lag_1                       | Variance: 2.57e+04\n",
      " 9. revenue_lag_7                       | Variance: 2.06e+04\n",
      "10. store_daily_sales                   | Variance: 1.34e+04\n",
      "\n",
      "Checking multicollinearity among top 10 features...\n",
      "Highly correlated feature pairs (>0.8):\n",
      "  sales_rolling_mean_3 <-> sales_rolling_max_3: 0.908\n",
      "  sales_rolling_mean_3 <-> sales_rolling_mean_7: 0.869\n",
      "  sales_rolling_mean_3 <-> sales_rolling_mean_14: 0.821\n",
      "  sales_rolling_mean_3 <-> sales_rolling_mean_30: 0.811\n",
      "  sales_rolling_max_3 <-> sales_rolling_mean_7: 0.806\n",
      "  sales_rolling_max_3 <-> sales_rolling_max_7: 0.821\n",
      "  sales_rolling_mean_7 <-> sales_rolling_mean_14: 0.946\n",
      "  sales_rolling_mean_7 <-> sales_rolling_mean_30: 0.935\n",
      "  sales_rolling_mean_7 <-> sales_rolling_max_7: 0.855\n",
      "  sales_rolling_mean_14 <-> sales_rolling_mean_30: 0.985\n",
      "  sales_rolling_mean_14 <-> sales_rolling_max_7: 0.810\n",
      "\n",
      "DATA QUALITY SUMMARY:\n",
      "  Total engineered features: 84\n",
      "  Best feature correlation: 0.7309\n",
      "  Features with >0.1 correlation: 20\n",
      "  Ready for model training: \n"
     ]
    }
   ],
   "source": [
    "# FEATURE QUALITY ANALYSIS\n",
    "print(\"Analyzing feature quality and correlations...\")\n",
    "\n",
    "# Remove rows with missing target variable\n",
    "analysis_df = engineered_df.dropna(subset=['sales_quantity']).copy()\n",
    "\n",
    "print(f\"Analysis dataset: {len(analysis_df):,} rows\")\n",
    "\n",
    "# Select numerical features for analysis\n",
    "numerical_features = analysis_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "numerical_features = [col for col in numerical_features if col != 'sales_quantity']  # Remove target\n",
    "\n",
    "print(f\"Numerical features for analysis: {len(numerical_features)}\")\n",
    "\n",
    "# Handle infinite values and missing data\n",
    "analysis_df = analysis_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Fill missing values with median for numerical columns\n",
    "missing_filled = 0\n",
    "for col in numerical_features:\n",
    "    if analysis_df[col].isnull().sum() > 0:\n",
    "        median_val = analysis_df[col].median()\n",
    "        missing_count = analysis_df[col].isnull().sum()\n",
    "        analysis_df[col] = analysis_df[col].fillna(median_val)\n",
    "        missing_filled += missing_count\n",
    "\n",
    "print(f\"Filled {missing_filled:,} missing values with median\")\n",
    "\n",
    "# Calculate correlations with target variable\n",
    "print(\"Calculating correlations with target variable...\")\n",
    "correlations = analysis_df[numerical_features + ['sales_quantity']].corr()['sales_quantity'].abs().sort_values(ascending=False)\n",
    "\n",
    "# Top 20 most correlated features\n",
    "top_features = correlations.head(21).drop('sales_quantity')  # Exclude target itself\n",
    "\n",
    "print(f\"\\nTOP 20 FEATURES CORRELATED WITH SALES:\")\n",
    "for i, (feature, corr) in enumerate(top_features.items(), 1):\n",
    "    print(f\"{i:2d}. {feature:<35} | Correlation: {corr:.4f}\")\n",
    "\n",
    "# Visualize top correlations\n",
    "fig = px.bar(\n",
    "    x=top_features.head(15).values,\n",
    "    y=top_features.head(15).index,\n",
    "    orientation='h',\n",
    "    title='Top 15 Features Correlated with Sales Quantity',\n",
    "    labels={'x': 'Absolute Correlation', 'y': 'Features'},\n",
    "    color=top_features.head(15).values,\n",
    "    color_continuous_scale='viridis'\n",
    ")\n",
    "fig.update_layout(height=600, showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# Feature importance based on variance\n",
    "feature_variance = analysis_df[numerical_features].var().sort_values(ascending=False)\n",
    "print(f\"\\nFEATURES WITH HIGHEST VARIANCE:\")\n",
    "for i, (feature, var) in enumerate(feature_variance.head(10).items(), 1):\n",
    "    print(f\"{i:2d}. {feature:<35} | Variance: {var:.2e}\")\n",
    "\n",
    "# Check for multicollinearity among top features\n",
    "print(f\"\\nChecking multicollinearity among top 10 features...\")\n",
    "top_10_features = top_features.head(10).index.tolist()\n",
    "correlation_matrix = analysis_df[top_10_features].corr()\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "high_corr_pairs = []\n",
    "for i in range(len(top_10_features)):\n",
    "    for j in range(i+1, len(top_10_features)):\n",
    "        corr_val = abs(correlation_matrix.iloc[i, j])\n",
    "        if corr_val > 0.8:  # High correlation threshold\n",
    "            high_corr_pairs.append((top_10_features[i], top_10_features[j], corr_val))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"Highly correlated feature pairs (>0.8):\")\n",
    "    for feat1, feat2, corr in high_corr_pairs:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr:.3f}\")\n",
    "else:\n",
    "    print(\"No highly correlated features found (good for model performance)\")\n",
    "\n",
    "print(f\"\\nDATA QUALITY SUMMARY:\")\n",
    "print(f\"  Total engineered features: {len(numerical_features)}\")\n",
    "print(f\"  Best feature correlation: {top_features.iloc[0]:.4f}\")\n",
    "print(f\"  Features with >0.1 correlation: {sum(top_features > 0.1)}\")\n",
    "print(f\"  Ready for model training: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2c7b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving engineered features and artifacts...\n",
      "Saved: engineered_features.csv\n",
      "Saved: label_encoders.pkl\n",
      "Saved: feature_sets.pkl\n",
      "Saved: feature_engineering_summary.json\n",
      "\n",
      "FEATURE ENGINEERING COMPLETE!\n",
      "======================================================================\n",
      "FINAL DATASET SUMMARY:\n",
      "   Total records: 89,482\n",
      "   Total features: 84\n",
      "   Best feature correlation: 0.7309 (sales_rolling_mean_3)\n",
      "   Data span: 2022-01-01 to 2023-12-31\n",
      "   Stores: 25\n",
      "   Products: 123\n",
      "   Categories: 6\n",
      "======================================================================\n",
      "READY FOR MODEL TRAINING PHASE!\n",
      "\n",
      "Files saved in data/processed/:\n",
      "   engineered_features.csv - Complete feature set\n",
      "   label_encoders.pkl - Categorical encoders\n",
      "   feature_sets.pkl - Feature groupings\n",
      "   feature_engineering_summary.json - Summary report\n",
      "\n",
      "NEXT PHASE PREVIEW:\n",
      "   Target variable: sales_quantity\n",
      "   Training features: 20 (top correlated)\n",
      "   Models: LightGBM + XGBoost\n",
      "   Evaluation: Time series cross-validation\n"
     ]
    }
   ],
   "source": [
    "# SAVE ENGINEERED FEATURES\n",
    "\n",
    "print(\"Saving engineered features and artifacts...\")\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create processed directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save the full engineered dataset\n",
    "engineered_df.to_csv('../data/processed/engineered_features.csv', index=False)\n",
    "print(\"Saved: engineered_features.csv\")\n",
    "\n",
    "# Save label encoders\n",
    "with open('../data/processed/label_encoders.pkl', 'wb') as f:\n",
    "   pickle.dump(label_encoders, f)\n",
    "print(\"Saved: label_encoders.pkl\")\n",
    "\n",
    "# Save feature lists for model training\n",
    "feature_sets = {\n",
    "   'all_features': numerical_features,\n",
    "   'top_features': top_features.head(50).index.tolist(),\n",
    "   'top_20_features': top_features.head(20).index.tolist(),\n",
    "   'time_features': time_features,\n",
    "   'lag_features': lag_features,\n",
    "   'rolling_features': rolling_features,\n",
    "   'price_features': price_features,\n",
    "   'promotion_features': promotion_features,\n",
    "   'aggregation_features': aggregation_features,\n",
    "   'encoded_features': encoded_features\n",
    "}\n",
    "\n",
    "with open('../data/processed/feature_sets.pkl', 'wb') as f:\n",
    "   pickle.dump(feature_sets, f)\n",
    "print(\"Saved: feature_sets.pkl\")\n",
    "\n",
    "# Create summary report with JSON-safe data types\n",
    "summary_report = {\n",
    "   'feature_engineering_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "   'dataset_info': {\n",
    "       'total_rows': int(len(engineered_df)),\n",
    "       'total_features': int(len(numerical_features)),\n",
    "       'date_range': {\n",
    "           'start': engineered_df['date'].min().strftime('%Y-%m-%d'),\n",
    "           'end': engineered_df['date'].max().strftime('%Y-%m-%d')\n",
    "       },\n",
    "       'stores': int(engineered_df['store_id'].nunique()),\n",
    "       'products': int(engineered_df['product_id'].nunique()),\n",
    "       'categories': int(engineered_df['category'].nunique()),\n",
    "       'provinces': int(engineered_df['province'].nunique())\n",
    "   },\n",
    "   'feature_breakdown': {\n",
    "       'time_features': int(len(time_features)),\n",
    "       'lag_features': int(len(lag_features)),\n",
    "       'rolling_features': int(len(rolling_features)),\n",
    "       'price_features': int(len(price_features)),\n",
    "       'promotion_features': int(len(promotion_features)),\n",
    "       'aggregation_features': int(len(aggregation_features)),\n",
    "       'encoded_features': int(len(encoded_features))\n",
    "   },\n",
    "   'top_features_correlation': {str(f): float(corr) for f, corr in top_features.head(20).items()},\n",
    "   'data_quality': {\n",
    "       'missing_values_filled': int(missing_filled),\n",
    "       'features_with_high_correlation': int(sum(top_features > 0.1)),\n",
    "       'multicollinearity_issues': int(len(high_corr_pairs) if 'high_corr_pairs' in locals() else 0)\n",
    "   },\n",
    "   'ready_for_modeling': True\n",
    "}\n",
    "\n",
    "with open('../data/processed/feature_engineering_summary.json', 'w') as f:\n",
    "   json.dump(summary_report, f, indent=2)\n",
    "print(\"Saved: feature_engineering_summary.json\")\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\nFEATURE ENGINEERING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL DATASET SUMMARY:\")\n",
    "print(f\"   Total records: {len(engineered_df):,}\")\n",
    "print(f\"   Total features: {len(numerical_features)}\")\n",
    "print(f\"   Best feature correlation: {top_features.iloc[0]:.4f} ({top_features.index[0]})\")\n",
    "print(f\"   Data span: {summary_report['dataset_info']['date_range']['start']} to {summary_report['dataset_info']['date_range']['end']}\")\n",
    "print(f\"   Stores: {summary_report['dataset_info']['stores']}\")\n",
    "print(f\"   Products: {summary_report['dataset_info']['products']}\")\n",
    "print(f\"   Categories: {summary_report['dataset_info']['categories']}\")\n",
    "print(\"=\"*70)\n",
    "print(\"READY FOR MODEL TRAINING PHASE!\")\n",
    "print(\"\\nFiles saved in data/processed/:\")\n",
    "print(\"   engineered_features.csv - Complete feature set\")\n",
    "print(\"   label_encoders.pkl - Categorical encoders\")\n",
    "print(\"   feature_sets.pkl - Feature groupings\")\n",
    "print(\"   feature_engineering_summary.json - Summary report\")\n",
    "\n",
    "# Quick preview of what we'll use for training\n",
    "print(\"\\nNEXT PHASE PREVIEW:\")\n",
    "print(f\"   Target variable: sales_quantity\")\n",
    "print(f\"   Training features: {len(feature_sets['top_20_features'])} (top correlated)\")\n",
    "print(f\"   Models: LightGBM + XGBoost\")\n",
    "print(f\"   Evaluation: Time series cross-validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b866d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
